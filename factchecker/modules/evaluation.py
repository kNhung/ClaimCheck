from .llm import prompt_ollama

judge_prompt = """HƯỚNG DẪN
Bạn được cung cấp 1 bản ghi. Hãy đưa ra phán quyết theo các bước sau:
1. Tóm tắt các ý chính từ BẢN GHI liên quan đến Claim.
2. Tổng hợp các ý chính trên và đưa ra phán quyết về claim.

PHÁN QUYẾT HỢP LỆ:
{options}

QUY TẮC CHỌN PHÁN QUYẾT:
{rules}

BẢN GHI:
{record}

In ra tóm tắt và phán quyết của bạn:
"""


verdict_extraction_prompt = """HƯỚNG DẪN
Bạn được cung cấp 1 đoạn phân tích. Hãy in ra phán quyết từ đoạn KẾT LUẬN sau.
Phán quyết phải thuộc một trong các tùy chọn dưới đây.

TÙY CHỌN PHÁN QUYẾT:
{options}

KẾT LUẬN:
{conclusion}

In ra duy nhất 1 từ phán quyết:
"""

def judge(record, decision_options, rules="", think=True):
    """
    Determines the veracity of a claim based on the provided record and decision options.

    Args:
        record (str): The record containing evidence for the judgement.
        decision_options (str): The available decision options to choose from.
        extra_rules (str): Additional rules to consider in the judgement.
        think (bool): Whether to use chain-of-thought (default True)
    Returns:
        str: The judgement generated by the LLM.
    """
    prompt = judge_prompt.format(record=record, options=decision_options, rules=rules)
    return prompt_ollama(prompt, think=think)

def extract_verdict(conclusion, decision_options, rules=""):
    """
    Extracts the verdict from the conclusion of a fact-check.

    Args:
        conclusion (str): The conclusion text from which to extract the verdict.
        decision_options (str): The available decision options to choose from.
        rules (str): Additional rules to consider in the extraction.
    
    Returns:
        str: The extracted verdict.
    """
    prompt = verdict_extraction_prompt.format(conclusion=conclusion, options=decision_options, rules=rules)
    return prompt_ollama(prompt, think=False)